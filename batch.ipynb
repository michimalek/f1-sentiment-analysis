{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from google.cloud import storage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv(csv_name):\n",
    "    bucket_path = \"de2022_f1_jmc\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_path)\n",
    "    if isinstance(csv_name, list):\n",
    "        for csv in csv_name:\n",
    "            bucket.blob(f'data/{csv}').download_to_filename(f\"../data/{csv}\")\n",
    "    else:\n",
    "        bucket.blob(f'data/{csv}').download_to_filename(f\"../data/{csv_name}\")\n",
    "\n",
    "download_csv([\"races.csv\",\"drivers.csv\", \"results.csv\", \"F1_tweets.csv\"])\n",
    "\n",
    "f1_tweet_data_path = \"../data/F1_tweets.csv\"\n",
    "f1_races_path = \"../data/races.csv\"\n",
    "f1_score_path = \"../data/results.csv\"\n",
    "f1_divers_path = \"../data/drivers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"500mb\") \\\n",
    "    .appName(\"app\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def get_data(file_name):\n",
    "    return spark.read.csv(file_name, header='true');\n",
    "\n",
    "races = get_data(f1_races_path);\n",
    "scores = get_data(f1_score_path);\n",
    "drivers = get_data(f1_divers_path);\n",
    "\n",
    "df = scores.join(races.alias(\"races\"), scores.raceId ==  races.raceId,\"left\") \\\n",
    "     .orderBy(col(\"races.raceId\")) \\\n",
    "     .join(drivers, scores.driverId == drivers.driverId, \"left\") \\\n",
    "     .join(races.alias(\"prevRace\"), col(\"prevRace.raceId\") == scores.raceId - 1, \"left\") \\\n",
    "     .filter(col(\"races.year\") == 2021) \\\n",
    "     .filter(scores.position == 1) \\\n",
    "     .select(scores.raceId, col(\"races.name\"), drivers.surname, to_date(col(\"races.date\"),\"yyyy-MM-dd\").alias(\"to_date\"), to_date(col(\"prevRace.date\"), \"yyyy-MM-dd\").alias(\"from_date\"));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector.\n",
    "bucket = \"de_jads_temp-401\"\n",
    "spark.conf.set('temporaryGcsBucket', bucket)\n",
    "\n",
    "df \\\n",
    "  .write.format('bigquery') \\\n",
    "  .option('table', 'de2022-362622.assignmentDatasets.racesSchedule') \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
