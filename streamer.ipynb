{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, concat, col, lit\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType\n",
    "from time import sleep\n",
    "from textblob import TextBlob\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"SparkStreamer\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# create the spark session, which is the entry point to Spark SQL engine.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "# Read the whole dataset as a batch\n",
    "df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka1:9093\") \\\n",
    "        .option(\"subscribe\", \"tweet\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .load()\n",
    "\n",
    "lines = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "def sentiment_analysis(df, batch_id):\n",
    "    tweet = TextBlob(df.select(col(\"tweet\")))\n",
    "    polarity = tweet.sentiment.polarity\n",
    "    tweet_sentiment = \"\"\n",
    "    if polarity > 0:\n",
    "        tweet_sentiment = 'positive'\n",
    "    elif polarity < 0:\n",
    "        tweet_sentiment = 'negative'\n",
    "    elif polarity == 0:\n",
    "        tweet_sentiment = 'neutral'\n",
    "    object = {\n",
    "        \"author\": df.select(col(\"user\")),\n",
    "        \"time\": df.select(col(\"race\")),\n",
    "        \"message\": df.select(col(\"text\")),\n",
    "        \"sentiment\": tweet_sentiment\n",
    "    }\n",
    "\n",
    "    df \\\n",
    "      .select(tweet_sentiment) \\\n",
    "      .write.format('bigquery') \\\n",
    "      .option('table', 'de2021-324520.labdataset.tweetSentiments') \\\n",
    "      .mode(\"overwrite\") \\\n",
    "      .save()\n",
    "\n",
    "query = df \\\n",
    "            .writeStream \\\n",
    "            .outputMode(\"complete\") \\\n",
    "            .option(\"checkpointLocation\", \"/home/jovyan/checkpoint\") \\\n",
    "            .foreachBatch(sentiment_analysis).start() \\\n",
    "            .start()\n",
    "\n",
    "try:\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    query.stop()\n",
    "    # Stop the spark context\n",
    "    spark.stop()\n",
    "    print(\"Stoped the streaming query and the spark context\")\n",
    "except:\n",
    "    query.stop()\n",
    "    # Stop the spark context\n",
    "    spark.stop()\n",
    "    print(\"Unexpected error\")\n",
    "    print(\"Stoped the streaming query and the spark context\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
